{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DLUSHmCf-CjbmoyWdF4FZsRoKhzBIXLr","timestamp":1736271204373}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e380bfd90de745ec8396cd4f3c75422f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_789f85fdcb27497f94b6c271d64e3552","IPY_MODEL_97f54329290f4521a0c8e734977e3b01","IPY_MODEL_d346228889014f79af0e47d41bf9b696"],"layout":"IPY_MODEL_eac9c1e8d2bf49c9848dca7d393c8189"}},"789f85fdcb27497f94b6c271d64e3552":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61d38acd86ea448bab8827e6b9539834","placeholder":"​","style":"IPY_MODEL_7f073fe888584aec84a2b42dce72825f","value":"tokenizer_config.json: 100%"}},"97f54329290f4521a0c8e734977e3b01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5beab1e8f2d24fbfac5b51241e7187d2","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f4504cb8d244abd9c0add13c2db9028","value":48}},"d346228889014f79af0e47d41bf9b696":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e268d49e3bf248a6b6d7e3b2f18b65bc","placeholder":"​","style":"IPY_MODEL_6b3c7ec3f3054074bca78ba9cb14f0bf","value":" 48.0/48.0 [00:00&lt;00:00, 2.55kB/s]"}},"eac9c1e8d2bf49c9848dca7d393c8189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d38acd86ea448bab8827e6b9539834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f073fe888584aec84a2b42dce72825f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5beab1e8f2d24fbfac5b51241e7187d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f4504cb8d244abd9c0add13c2db9028":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e268d49e3bf248a6b6d7e3b2f18b65bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b3c7ec3f3054074bca78ba9cb14f0bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c88ebb0e9674db6a531a8f5f3520148":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc21b16fb5d84c8597ef71977d33352c","IPY_MODEL_b1761e9b72824caeb51f938236cd1287","IPY_MODEL_eeea91e5992443a6be9a4f89382806d5"],"layout":"IPY_MODEL_fe414a922fa2412484dfeead5b918ddd"}},"fc21b16fb5d84c8597ef71977d33352c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f3af091bc58412cb5b8c8189fca0991","placeholder":"​","style":"IPY_MODEL_6b253803b4364aa6980ef56f180fde89","value":"vocab.txt: 100%"}},"b1761e9b72824caeb51f938236cd1287":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ff9f77b16694e1e936074cd6e25c27c","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_affe23762e13422b90252ddf11d422a0","value":231508}},"eeea91e5992443a6be9a4f89382806d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f05943a43485428b8ee596df28a74523","placeholder":"​","style":"IPY_MODEL_4d49a8ace89347e4938c99e676fd2996","value":" 232k/232k [00:00&lt;00:00, 7.81MB/s]"}},"fe414a922fa2412484dfeead5b918ddd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f3af091bc58412cb5b8c8189fca0991":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b253803b4364aa6980ef56f180fde89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ff9f77b16694e1e936074cd6e25c27c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"affe23762e13422b90252ddf11d422a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f05943a43485428b8ee596df28a74523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d49a8ace89347e4938c99e676fd2996":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48fd699f5da44d838c831553811bd8a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d13a44f7dde74900a3ab20ec3a588ce7","IPY_MODEL_6cd825caed4d4008b09a51b59a74d69b","IPY_MODEL_1a4546e933dd4ca89f9fce27df323833"],"layout":"IPY_MODEL_7bb123e7587f467ab80b41fe9471c257"}},"d13a44f7dde74900a3ab20ec3a588ce7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce3d9b214044446094d90554eecc8bbf","placeholder":"​","style":"IPY_MODEL_f88c149d0df04e998d02c102549a471e","value":"tokenizer.json: 100%"}},"6cd825caed4d4008b09a51b59a74d69b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbac7494aecb476a9c411be898912f9c","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81de454af95c4347aa37f211040a6e68","value":466062}},"1a4546e933dd4ca89f9fce27df323833":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe256dd75171497db75d2b7965ee5992","placeholder":"​","style":"IPY_MODEL_58604959db8e4ed1b4f76780f84ca951","value":" 466k/466k [00:00&lt;00:00, 12.7MB/s]"}},"7bb123e7587f467ab80b41fe9471c257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce3d9b214044446094d90554eecc8bbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f88c149d0df04e998d02c102549a471e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbac7494aecb476a9c411be898912f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81de454af95c4347aa37f211040a6e68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe256dd75171497db75d2b7965ee5992":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58604959db8e4ed1b4f76780f84ca951":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a2d37ca2a174099b9893bc5df89dc4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68d139640f5c4794ae6645f06abf2479","IPY_MODEL_da7490a6e9354065b23209eafedef8bf","IPY_MODEL_34aebc6577ca44ba83cefcad39ff941f"],"layout":"IPY_MODEL_b89f9ca7ff7f41909bc39083f978964b"}},"68d139640f5c4794ae6645f06abf2479":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fc11742d6b6485ea56eafd3d105a5f3","placeholder":"​","style":"IPY_MODEL_2e87a738396e45be871ae4e38dd94cf6","value":"config.json: 100%"}},"da7490a6e9354065b23209eafedef8bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a96d49438754b93a20ee46b287cb573","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e0a08a8126142f0a2edd9d16315f1a3","value":570}},"34aebc6577ca44ba83cefcad39ff941f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0902d38f22b843fc8e2afd10bf8305d5","placeholder":"​","style":"IPY_MODEL_06ac5e87583c4784b4bf6b7c94667f8d","value":" 570/570 [00:00&lt;00:00, 24.4kB/s]"}},"b89f9ca7ff7f41909bc39083f978964b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc11742d6b6485ea56eafd3d105a5f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e87a738396e45be871ae4e38dd94cf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a96d49438754b93a20ee46b287cb573":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0a08a8126142f0a2edd9d16315f1a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0902d38f22b843fc8e2afd10bf8305d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06ac5e87583c4784b4bf6b7c94667f8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e38b8d3d6d94c2f8198ffa5baee990a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9eb5e94d2d3b4c74b5213817ceca8219","IPY_MODEL_8665f1e0c67a407a9aa92fdffebe8559","IPY_MODEL_72e5b6b8cdc34c3d90d737327aacaaec"],"layout":"IPY_MODEL_d6d6a3d70ae94f7f94ed9139ec9816b9"}},"9eb5e94d2d3b4c74b5213817ceca8219":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_788e697a575b43d68af49bb155eb71dd","placeholder":"​","style":"IPY_MODEL_0a404051ac1d48a6bea51ed54b4a6cb0","value":"model.safetensors: 100%"}},"8665f1e0c67a407a9aa92fdffebe8559":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56c47de9c6a34d26bcb98b3d60262024","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cdd8fd9f3bc64d18b741140620572648","value":440449768}},"72e5b6b8cdc34c3d90d737327aacaaec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_521b496a39504446b17ece868085192d","placeholder":"​","style":"IPY_MODEL_def5722bfc8d45dd862ff9775586c0bc","value":" 440M/440M [00:02&lt;00:00, 151MB/s]"}},"d6d6a3d70ae94f7f94ed9139ec9816b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788e697a575b43d68af49bb155eb71dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a404051ac1d48a6bea51ed54b4a6cb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56c47de9c6a34d26bcb98b3d60262024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdd8fd9f3bc64d18b741140620572648":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"521b496a39504446b17ece868085192d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def5722bfc8d45dd862ff9775586c0bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDf6XaZ-P4Z8","outputId":"91522a95-8710-49d5-be13-748d694b837d","executionInfo":{"status":"ok","timestamp":1736271775212,"user_tz":-60,"elapsed":18143,"user":{"displayName":"Jonatan Kasperczak","userId":"03152155156041437727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","data_dir = \"/content/drive/My Drive/studia/PW/NLP\""]},{"cell_type":"code","source":["training_percent = 0.8\n","testing_percent = 0.2\n","dataset_path = \"/content/drive/My Drive/studia/PW/NLP/Phishing_Email.csv\"\n","intended_device = \"gpu\" #cpu or gpu\n","learning_rate = 2e-5\n","rand_seed = 2025\n","max_len = 80\n","batch_size = 32\n","epochs = 2"],"metadata":{"id":"A9hrvOBiQx_-","executionInfo":{"status":"ok","timestamp":1736271779637,"user_tz":-60,"elapsed":277,"user":{"displayName":"Jonatan Kasperczak","userId":"03152155156041437727"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import time\n","import datetime\n","import gc\n","import random\n","import nltk\n","from nltk.corpus import stopwords\n","import re\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","import transformers\n","from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup"],"metadata":{"id":"mq3nBSueb-7j","executionInfo":{"status":"ok","timestamp":1736271807414,"user_tz":-60,"elapsed":25282,"user":{"displayName":"Jonatan Kasperczak","userId":"03152155156041437727"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def preprocess_dataset(path):\n","    nltk.download('stopwords')\n","    sw = stopwords.words('english')\n","    df = pd.read_csv(path)\n","\n","    df['Email Text'] = df['Email Text'].astype('str')\n","    df['Email Type'] = df['Email Type'].astype('str')\n","    mapping = {'Safe Email': 0, 'Phishing Email': 1}\n","    df['Email Type'] = df['Email Type'].map(mapping)\n","    df.rename(columns={'Email Type': 'label'}, inplace=True)\n","    df.rename(columns={'Email Text': 'text'}, inplace=True)\n","\n","    #clean message bodies\n","    df['text'] = df['text'].apply(lambda x: clean_text(x, sw))\n","    return df\n","\n","\n","def clean_text(text,sw):\n","\n","    # delete new lines and tabs\n","    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n","    #lowercase\n","    text = text.lower()\n","    #change not used symbols to space\n","    text = re.sub(r\"[^a-zA-Z?.!,$]+\", \" \", text)\n","    #remove links\n","    text = re.sub(r\"http\\S+\", \"\",text)\n","    text = re.sub(r\"http\", \"\",text)\n","    text = re.sub(r\"enron\", \"\",text)\n","    #remove html tags\n","    html=re.compile(r'<.*?>')\n","    text = html.sub(r'',text)\n","    #remove punctuations\n","    #punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_' + \"#\"\n","    #for p in punctuations:\n","    #    text = text.replace(p,'')\n","    #text = re.sub(r'[{}]'.format(re.escape(punctuations)), '', text)\n","    text = [word.lower() for word in text.split() if word.lower() not in sw]\n","    text = \" \".join(text) #removing stopwords\n","    return text\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","def calc_max_len(text):\n","    # get length of all the messages in the train set\n","    seq_len = [len(i.split()) for i in text]\n","    hist, bin_edges = np.histogram(seq_len, bins=len(seq_len))\n","    hist_table = pd.DataFrame({'Message lenght': [f\"{int(bin_edges[i])} - {int(bin_edges[i+1])}\" for i in range(len(bin_edges)-1)],'Frequency': hist})\n","    print(hist_table)\n","\n","    # Calculate cumulative frequency\n","    cumulative_frequency = np.cumsum(hist)\n","\n","    # Total frequency\n","    total_frequency = cumulative_frequency[-1]\n","\n","    # Find the bin edge that covers the desired percentage\n","    cutoff_frequency = total_frequency * 0.5 #0.9\n","    bin_index = np.searchsorted(cumulative_frequency, cutoff_frequency)\n","\n","    # Return the upper edge of the bin covering the specified percentage\n","    return int(bin_edges[bin_index + 1])\n","\n","\n","def main():\n","    if intended_device == \"gpu\":\n","        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    elif intended_device == \"cpu\":\n","        device = torch.device(\"cpu\")\n","    print(\"Using device: \"+str(device))\n","    #preprocess\n","    df = preprocess_dataset(dataset_path)\n","\n","    print(\"Loaded dataset, info:\")\n","    print(df.info())\n","\n","    emails = df.text.values\n","    labels = df.label.values\n","\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","    input_ids = []\n","    attention_masks = []\n","\n","    #max_len = calc_max_len(emails)\n","    print(max_len)\n","\n","\n","    # for each email tokenize, add [CLS] and [SEP] tokens, maps tokens to ids, pad or truncate and create attention masks for [PAD] tokens\n","    for email in emails:\n","        encoded_dict = tokenizer.encode_plus(\n","                            email,\n","                            add_special_tokens = True, #[CLS] and [SEP]\n","                            max_length = max_len, #pad & truncate all sentences.\n","                            pad_to_max_length = True,\n","                            return_attention_mask = True,   #attention masks.\n","                            return_tensors = 'pt',     # Return pytorch tensors\n","                    )\n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    #convert lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    #convert to TensorDataset.\n","    dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","    #training/testing set split\n","    train_size = int(training_percent * len(dataset))\n","    val_size = int(testing_percent * len(dataset))\n","\n","    #split randomly\n","    train_dataset, tmp_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(rand_seed))\n","    val_dataset, test_dataset_tmp = random_split(tmp_dataset, [int(training_percent * len(tmp_dataset)), int(testing_percent * len(tmp_dataset))], generator=torch.Generator().manual_seed(rand_seed))\n","\n","    #DataLoaders for training and validation sets.\n","    #samples in random order.\n","    train_dataloader = DataLoader(\n","                train_dataset,\n","                sampler = RandomSampler(train_dataset),\n","                batch_size = batch_size\n","                )\n","\n","    #for validation sequentially.\n","    validation_dataloader = DataLoader(\n","                val_dataset,\n","                sampler = SequentialSampler(val_dataset),\n","                batch_size = batch_size\n","                )\n","\n","    #load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n","    model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", #12-layer BERT model, with an uncased vocab\n","        num_labels = 2, #2 for binary classification.\n","        output_attentions = False, #whether the model returns attentions weights.\n","        output_hidden_states = False, #whether the model returns all hidden-states.\n","    )\n","\n","    model = model.to(device)\n","\n","    optimizer = AdamW(model.parameters(),\n","                  lr = learning_rate,\n","                  eps = 1e-8 #default\n","                )\n","\n","    #total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","\n","    #learning rate scheduler.\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps = 0, # Default value in run_glue.py\n","                                                num_training_steps = total_steps)\n","\n","\n","\n","    random.seed(rand_seed)\n","    np.random.seed(rand_seed)\n","    torch.manual_seed(rand_seed)\n","    torch.cuda.manual_seed_all(rand_seed)\n","    training_stats = []\n","    total_t0 = time.time()\n","\n","    # For each epoch...\n","    for epoch_i in range(0, epochs):\n","        #training: perform one full pass over the training set.\n","        print(\"\")\n","        print('Epoch {:} / {:} '.format(epoch_i + 1, epochs))\n","        print('Training...')\n","        # Measure how long the training epoch takes.\n","        t0 = time.time()\n","        total_train_loss = 0\n","        model.train()\n","        for step, batch in enumerate(train_dataloader):\n","            # Unpack this training batch from our dataloader.\n","            # As we unpack the batch, we'll also copy each tensor to the device using the `to` method.\n","            # `batch` contains three pytorch tensors:\n","            #   [0]: input ids\n","            #   [1]: attention masks\n","            #   [2]: labels\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","            optimizer.zero_grad()\n","            output = model(b_input_ids,\n","                                token_type_ids=None,\n","                                attention_mask=b_input_mask,\n","                                labels=b_labels)\n","            loss = output.loss\n","            total_train_loss += loss.item()\n","            # Perform a backward pass to calculate the gradients.\n","            loss.backward()\n","            # Clip the norm of the gradients to 1.0.\n","            # This is to help prevent the \"exploding gradients\" problem.\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            # Update parameters and take a step using the computed gradient.\n","            # The optimizer dictates the \"update rule\"--how the parameters are\n","            # modified based on their gradients, the learning rate, etc.\n","            optimizer.step()\n","            # Update the learning rate.\n","            scheduler.step()\n","\n","        # Calculate the average loss over all of the batches.\n","        avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","        # Measure how long this epoch took.\n","        training_time = format_time(time.time() - t0)\n","        print(\"\")\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","        print(\"  Training epcoh took: {:}\".format(training_time))\n","        #               Validation\n","        # After the completion of each training epoch, measure our performance on\n","        # our validation set.\n","        print(\"\")\n","        print(\"Running Validation...\")\n","        t0 = time.time()\n","        # Put the model in evaluation mode--the dropout layers behave differently\n","        # during evaluation.\n","        model.eval()\n","        # Tracking variables\n","        total_eval_accuracy = 0\n","        best_eval_accuracy = 0\n","        total_eval_loss = 0\n","        nb_eval_steps = 0\n","        # Evaluate data for one epoch\n","        for batch in validation_dataloader:\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","            # Tell pytorch not to bother with constructing the compute graph during\n","            # the forward pass, since this is only needed for backprop (training).\n","            with torch.no_grad():\n","                output= model(b_input_ids,\n","                                    token_type_ids=None,\n","                                    attention_mask=b_input_mask,\n","                                    labels=b_labels)\n","            loss = output.loss\n","            total_eval_loss += loss.item()\n","            # Move logits and labels to CPU if we are using GPU\n","            logits = output.logits\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","            # Calculate the accuracy for this batch of test sentences, and\n","            # accumulate it over all batches.\n","            total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        # Report the final accuracy for this validation run.\n","        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","        # Calculate the average loss over all of the batches.\n","        avg_val_loss = total_eval_loss / len(validation_dataloader)\n","        # Measure how long the validation run took.\n","        validation_time = format_time(time.time() - t0)\n","        if avg_val_accuracy > best_eval_accuracy:\n","            torch.save(model, 'bert_model')\n","            best_eval_accuracy = avg_val_accuracy\n","        #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","        #print(\"  Validation took: {:}\".format(validation_time))\n","        # Record all statistics from this epoch.\n","        training_stats.append(\n","            {\n","                'epoch': epoch_i + 1,\n","                'Training Loss': avg_train_loss,\n","                'Valid. Loss': avg_val_loss,\n","                'Valid. Accur.': avg_val_accuracy,\n","                'Training Time': training_time,\n","                'Validation Time': validation_time\n","            }\n","        )\n","    print(\"\")\n","    print(\"Training complete!\")\n","\n","    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n","\n","    model = torch.load('bert_model')\n","\n","    test_input_ids, test_attention_masks, test_labels = zip(*test_dataset_tmp)\n","    # Tworzenie nowego TensorDataset bez etykiet\n","    test_dataset = TensorDataset(torch.stack(test_input_ids), torch.stack(test_attention_masks))\n","    test_labels_list = [label.item() for label in test_labels]\n","\n","\n","    test_dataloader = DataLoader(\n","                test_dataset, # The validation samples.\n","                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n","                batch_size = batch_size # Evaluate with this batch size.\n","            )\n","\n","\n","    predictions = []\n","    for batch in test_dataloader:\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            with torch.no_grad():\n","                output= model(b_input_ids,\n","                                    token_type_ids=None,\n","                                    attention_mask=b_input_mask)\n","                logits = output.logits\n","                logits = logits.detach().cpu().numpy()\n","                pred_flat = np.argmax(logits, axis=1).flatten()\n","\n","                predictions.extend(list(pred_flat))\n","\n","\n","    print(\"Test results: \")\n","    conf_matrix = confusion_matrix(test_labels_list, predictions)\n","\n","    confusion_df = pd.DataFrame(\n","        conf_matrix,\n","        index=[\"Actual Negative\", \"Actual Positive\"],\n","        columns=[\"Predicted Negative\", \"Predicted Positive\"]\n","    )\n","\n","    # Display the labeled confusion matrix\n","    print(\"Confusion Matrix:\")\n","    print(confusion_df)\n","\n","\n","    # Generowanie raportu\n","    report = classification_report(test_labels_list, predictions, target_names=[\"Negative\", \"Positive\"])\n","    print(\"\\nClassification Report:\")\n","    print(report)"],"metadata":{"id":"w41ndHfPcCtG","executionInfo":{"status":"ok","timestamp":1736271809626,"user_tz":-60,"elapsed":294,"user":{"displayName":"Jonatan Kasperczak","userId":"03152155156041437727"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":778,"referenced_widgets":["e380bfd90de745ec8396cd4f3c75422f","789f85fdcb27497f94b6c271d64e3552","97f54329290f4521a0c8e734977e3b01","d346228889014f79af0e47d41bf9b696","eac9c1e8d2bf49c9848dca7d393c8189","61d38acd86ea448bab8827e6b9539834","7f073fe888584aec84a2b42dce72825f","5beab1e8f2d24fbfac5b51241e7187d2","1f4504cb8d244abd9c0add13c2db9028","e268d49e3bf248a6b6d7e3b2f18b65bc","6b3c7ec3f3054074bca78ba9cb14f0bf","6c88ebb0e9674db6a531a8f5f3520148","fc21b16fb5d84c8597ef71977d33352c","b1761e9b72824caeb51f938236cd1287","eeea91e5992443a6be9a4f89382806d5","fe414a922fa2412484dfeead5b918ddd","9f3af091bc58412cb5b8c8189fca0991","6b253803b4364aa6980ef56f180fde89","8ff9f77b16694e1e936074cd6e25c27c","affe23762e13422b90252ddf11d422a0","f05943a43485428b8ee596df28a74523","4d49a8ace89347e4938c99e676fd2996","48fd699f5da44d838c831553811bd8a1","d13a44f7dde74900a3ab20ec3a588ce7","6cd825caed4d4008b09a51b59a74d69b","1a4546e933dd4ca89f9fce27df323833","7bb123e7587f467ab80b41fe9471c257","ce3d9b214044446094d90554eecc8bbf","f88c149d0df04e998d02c102549a471e","fbac7494aecb476a9c411be898912f9c","81de454af95c4347aa37f211040a6e68","fe256dd75171497db75d2b7965ee5992","58604959db8e4ed1b4f76780f84ca951","9a2d37ca2a174099b9893bc5df89dc4c","68d139640f5c4794ae6645f06abf2479","da7490a6e9354065b23209eafedef8bf","34aebc6577ca44ba83cefcad39ff941f","b89f9ca7ff7f41909bc39083f978964b","3fc11742d6b6485ea56eafd3d105a5f3","2e87a738396e45be871ae4e38dd94cf6","6a96d49438754b93a20ee46b287cb573","2e0a08a8126142f0a2edd9d16315f1a3","0902d38f22b843fc8e2afd10bf8305d5","06ac5e87583c4784b4bf6b7c94667f8d","0e38b8d3d6d94c2f8198ffa5baee990a","9eb5e94d2d3b4c74b5213817ceca8219","8665f1e0c67a407a9aa92fdffebe8559","72e5b6b8cdc34c3d90d737327aacaaec","d6d6a3d70ae94f7f94ed9139ec9816b9","788e697a575b43d68af49bb155eb71dd","0a404051ac1d48a6bea51ed54b4a6cb0","56c47de9c6a34d26bcb98b3d60262024","cdd8fd9f3bc64d18b741140620572648","521b496a39504446b17ece868085192d","def5722bfc8d45dd862ff9775586c0bc"]},"id":"LzqfLFg3jKE1","outputId":"4bd7009e-04ae-4113-c863-518b26711265"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded dataset, info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 18650 entries, 0 to 18649\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   Unnamed: 0  18650 non-null  int64 \n"," 1   text        18650 non-null  object\n"," 2   label       18650 non-null  int64 \n","dtypes: int64(2), object(1)\n","memory usage: 437.2+ KB\n","None\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e380bfd90de745ec8396cd4f3c75422f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c88ebb0e9674db6a531a8f5f3520148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48fd699f5da44d838c831553811bd8a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2d37ca2a174099b9893bc5df89dc4c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["80\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e38b8d3d6d94c2f8198ffa5baee990a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 / 2 \n","Training...\n"]}]}]}